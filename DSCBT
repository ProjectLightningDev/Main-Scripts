import discord
from discord.ext import commands
import requests
import asyncio

# Your DeepInfra API key (replace with yours)
api_key = '88nVCIhckYXfDs9St2LjUFuIq3j1gJQu'

# Set up the bot
intents = discord.Intents.default()
intents.message_content = True

bot = commands.Bot(command_prefix="/", intents=intents)

# Helper function to split long code into smaller parts
def split_code_into_parts(code):
    # Split the code into parts of max 1024 characters (Discord's limit)
    return [code[i:i+1024] for i in range(0, len(code), 1024)]

# Create the embed with a code response
# Create the embed with a code response
def create_code_embed(code_part):
    embed = discord.Embed(title="Generated Code", color=discord.Color.blue())
    code_parts = split_code_into_parts(code_part)
    for part in code_parts:
        embed.add_field(name="Code:", value=f"python\n{part}\n", inline=False)
    return embed
# Create the embed with help text
def create_help_embed():
    embed = discord.Embed(title="How to Use the Commands", color=discord.Color.green())
    embed.add_field(name="/codegpt", value="Get code suggestions, assistance, or debugging help.", inline=False)
    embed.add_field(name="/debug", value="Help debug code in any language.", inline=False)
    embed.add_field(name="/explain", value="Explain the code you provide.", inline=False)
    return embed

# Send the long code message with pagination (Next/Previous)
async def send_code_parts(interaction, code_parts):
    current_page = 0

    async def send_page(page):
        # Check if the code part fits in an embed (length <= 1024)
        code_part = code_parts[page]
        if len(code_part) <= 1024:
            embed = create_code_embed(code_part)
            await interaction.followup.send(embed=embed)
        else:
            # If code exceeds embed limit, send as plain message instead
            await interaction.followup.send(f"python\n{code_part}\n")

    await send_page(current_page)

# Register the slash command for code-related requests
@bot.tree.command(name="codegpt", description="Get code suggestions, assistance, or debugging help.")
async def codegpt(interaction: discord.Interaction, prompt: str):
    # Acknowledge the command
    await interaction.response.defer()  # This defers the response, allowing us to send follow-ups.

    # Prepare the data to send to DeepInfra's Qwen API
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    payload = {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",  # Using your specific model
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }

    try:
        # Send the request to the DeepInfra API (Asynchronous)
        response = await asyncio.to_thread(requests.post, "https://api.deepinfra.com/v1/openai/chat/completions", headers=headers, json=payload)

        if response.status_code == 200:
            data = response.json()
            output = data.get("choices", [{}])[0].get("message", {}).get("content", "No response")
            code_parts = split_code_into_parts(output)

            # Send the response in parts if it's too long
            await send_code_parts(interaction, code_parts)
        else:
            error_message = f"Error: {response.status_code} - {response.text}"
            await interaction.followup.send(f"API Error: {error_message}")
            print(error_message)

    except requests.exceptions.RequestException as e:
        # Catch any exceptions and print error
        await interaction.followup.send(f"Error with the API request: {str(e)}")
        print(f"Error with the API request: {str(e)}")
    except Exception as e:
        # Catch any other general exceptions
        await interaction.followup.send(f"Unexpected error: {str(e)}")
        print(f"Unexpected error: {str(e)}")

# Register the slash command for debugging code
@bot.tree.command(name="debug", description="Help debug code in any language.")
async def debug(interaction: discord.Interaction, code: str):
    # Acknowledge the command
    await interaction.response.defer()

    # Prepare the data to send for debugging
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    payload = {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "messages": [
            {
                "role": "user",
                "content": f"Debug the following code: {code}"
            }
        ]
    }

    try:
        # Send the request to the DeepInfra API (Asynchronous)
        response = await asyncio.to_thread(requests.post, "https://api.deepinfra.com/v1/openai/chat/completions", headers=headers, json=payload)

        if response.status_code == 200:
            data = response.json()
            output = data.get("choices", [{}])[0].get("message", {}).get("content", "No response")
            code_parts = split_code_into_parts(output)

            # Send the response in parts if it's too long
            await send_code_parts(interaction, code_parts)
        else:
            error_message = f"Error: {response.status_code} - {response.text}"
            await interaction.followup.send(f"API Error: {error_message}")
            print(error_message)

    except requests.exceptions.RequestException as e:
        # Catch any exceptions and print error
        await interaction.followup.send(f"Error with the API request: {str(e)}")
        print(f"Error with the API request: {str(e)}")
    except Exception as e:
        # Catch any other general exceptions
        await interaction.followup.send(f"Unexpected error: {str(e)}")
        print(f"Unexpected error: {str(e)}")

# Register the slash command for explaining code
@bot.tree.command(name="explain", description="Explain the code you provide.")
async def explain(interaction: discord.Interaction, code: str):
    # Acknowledge the command
    await interaction.response.defer()

    # Prepare the data to send for explanation
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }

    payload = {
        "model": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "messages": [
            {
                "role": "user",
                "content": f"Explain the following code: {code}"
            }
        ]
    }

    try:
        # Send the request to the DeepInfra API (Asynchronous)
        response = await asyncio.to_thread(requests.post, "https://api.deepinfra.com/v1/openai/chat/completions", headers=headers, json=payload)

        if response.status_code == 200:
            data = response.json()
            output = data.get("choices", [{}])[0].get("message", {}).get("content", "No response")
            code_parts = split_code_into_parts(output)

            # Send the response in parts if it's too long
            await send_code_parts(interaction, code_parts)
        else:
            error_message = f"Error: {response.status_code} - {response.text}"
            await interaction.followup.send(f"API Error: {error_message}")
            print(error_message)

    except requests.exceptions.RequestException as e:
        # Catch any exceptions and print error
        await interaction.followup.send(f"Error with the API request: {str(e)}")
        print(f"Error with the API request: {str(e)}")
    except Exception as e:
        # Catch any other general exceptions
        await interaction.followup.send(f"Unexpected error: {str(e)}")
        print(f"Unexpected error: {str(e)}")

# Fallback: if someone sends a general question or message
@bot.event
async def on_message(message):
    if message.author == bot.user:
        return  # Ignore messages from the bot itself

    # If it's not a command, just reply to the message like a normal bot
    if not message.content.startswith("/"):  # If not a command
        response = "I'm here to help! If you need help with code, debugging, or general questions, just ask!"
        await message.reply(response)

    # Process commands as well
    await bot.process_commands(message)

# Run the bot
bot.run('MTMzOTM5MzA5NDg5ODE1OTcwNg.GqCRin.y6gOONuRcgYtYC-PnmuGEMfXKPhvbR5rGd6P0s')
